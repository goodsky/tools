{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusion3Pipeline\n",
    "\n",
    "pipe = StableDiffusion3Pipeline.from_pretrained(\"stabilityai/stable-diffusion-3.5-medium\", torch_dtype=torch.bfloat16)\n",
    "pipe = pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline, LCMScheduler\n",
    "import torch\n",
    "\n",
    "model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "lcm_lora_id = \"latent-consistency/lcm-lora-sdxl\"\n",
    "pipe = DiffusionPipeline.from_pretrained(model_id, use_safetensors=True, variant=\"fp16\", torch_dtype=torch.float16)\n",
    "pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "pipe.load_lora_weights(lcm_lora_id, adapter_name=\"lora\")\n",
    "\n",
    "pipe.set_adapters([\"lora\"], adapter_weights=[1.0])\n",
    "pipe.enable_model_cpu_offload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "prompt = \"They were the last two people on Earth, and the first two people on Mars.\"\n",
    "num_images = 3\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")\n",
    "for i in range(num_images):\n",
    "    img = pipe(\n",
    "        prompt=prompt,\n",
    "        num_inference_steps=8,\n",
    "        guidance_scale=1.5,\n",
    "    ).images[0]\n",
    "    \n",
    "    img.save(f\"sdxl/lcm_lora_{timestamp}_{i}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import AutoPipelineForText2Image, DEISMultistepScheduler\n",
    "import torch\n",
    "\n",
    "pipe = AutoPipelineForText2Image.from_pretrained('Lykon/dreamshaper-xl-lightning', torch_dtype=torch.float16, variant=\"fp16\")\n",
    "pipe.scheduler = DEISMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "pipe.enable_model_cpu_offload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "prompt = \"A girl smiling\"\n",
    "negative_prompt = \"off center\"\n",
    "num_images = 3\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")\n",
    "for i in range(num_images):\n",
    "    img = pipe(\n",
    "        prompt=prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "        num_inference_steps=4,\n",
    "        guidance_scale=2,\n",
    "    ).images[0]\n",
    "    \n",
    "    img.save(f\"sdxl/ds_lightning_{timestamp}_{i}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
